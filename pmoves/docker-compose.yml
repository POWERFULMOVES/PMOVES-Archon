# =============================================================================
# PMOVES.AI - Hardened Architecture Docker Compose Configuration
# =============================================================================
#
# Network Architecture (5-Tier Isolation Model):
# -----------------------------------------------
# 1. pmoves_data  - Data tier (vector DBs, graph DBs, search indexes)
# 2. pmoves_api   - API tier (REST/GraphQL endpoints, gateways)
# 3. pmoves_app   - Application tier (business logic services)
# 4. pmoves_bus   - Message bus tier (NATS event streaming)
# 5. pmoves_monitoring - Observability tier (Prometheus, Grafana, Loki)
#
# Additional Networks:
# - pmoves        - Legacy compatibility bridge (Supabase connectivity)
# - supabase_net  - Supabase CLI local stack (external dependency)
#
# Service Tier Assignment:
# ------------------------
# - Services connect ONLY to their required tiers (principle of least privilege)
# - Cross-tier communication goes through gateways (not direct DB access)
# - External access via host.docker.internal for local development
#
# Environment Variable Strategy:
# ------------------------------
# - env.shared      - Common configuration (URLs, ports, service names)
# - env.tier-data   - Data tier credentials (Qdrant, Neo4j, Meilisearch)
# - env.tier-api    - API tier credentials (Hi-RAG, TensorZero)
# - env.tier-llm    - LLM provider credentials (via TensorZero gateway)
# - env.tier-worker - Background worker credentials (extract, langextract)
# - env.tier-media  - Media processing credentials (whisper, YOLO)
# - env.tier-agent  - Agent orchestration credentials (Agent Zero, Archon)
# - env.tier-ui     - Frontend credentials (React apps)
#
# YAML anchors below enable tier-based env loading via the <<: merge pattern.
# =============================================================================
#
# YAML anchors for tier-based env file loading
# Format: Maps with env_file key for <<: merge pattern
# Tier architecture isolates secrets by service category (data, api, llm, worker, media, agent)
x-env-tier-data: &id001
  env_file:
    - env.shared
    - env.tier-data

x-env-tier-api: &id002
  env_file:
    - env.shared
    - env.tier-api

x-env-tier-llm: &id006
  env_file:
    - env.shared
    - env.tier-llm

x-env-tier-worker: &id003
  env_file:
    - env.shared
    - env.tier-worker

x-env-tier-media: &id004
  env_file:
    - env.shared
    - env.tier-media

x-env-tier-agent: &id005
  env_file:
    - env.shared
    - env.tier-agent

x-env-tier-ui: &id007
  env_file:
    - env.shared
    - env.tier-ui

x-env-tier-supabase: &id008
  env_file:
    - env.shared
    - env.tier-supabase

# =============================================================================
# CONTAINER HARDENING TEMPLATES (Security Baseline)
# =============================================================================
#
# These YAML anchors provide container security hardening for all services.
# Apply to service definitions using the <<: *anchor-name merge pattern.
#
# Hardening Options Explained:
# ----------------------------
# - cap_drop: [ALL] - Drop all Linux capabilities (principle of least privilege)
# - cap_add: [NET_BIND_SERVICE] - Add back only specific capabilities needed
# - read_only: true - Mount container rootfs as read-only (prevents modification)
# - security_opt: [no-new-privileges:true] - Prevent privilege escalation via setuid/setgid
# - tmpfs: - Mount temporary filesystems with noexec/nosuid flags
#
# When to Use Each Template:
# --------------------------
# 1. x-hardening (&hardening) - For stateless, read-only services:
#    - API gateways, proxies, pure compute services
#    - Services that don't write to local filesystem
#    - Example: presign, render-webhook, model-registry
#
# 2. x-hardening-rw (&hardening-rw) - For services with write requirements:
#    - Databases (need data directory writes)
#    - Log aggregators (need log file writes)
#    - Services with tmp/cache volumes
#    - Example: postgres, neo4j, nats
#
# Adding Additional Capabilities:
# --------------------------------
# If a service needs additional capabilities beyond NET_BIND_SERVICE:
#
#   service-name:
#     <<: *hardening  # Start with base template
#     cap_add:
#       - NET_BIND_SERVICE  # From template
#       - CHOWN            # Add this if needed for file ownership
#       - SETGID           # Add this if needed for group operations
#       - SETUID           # Add this if needed for user operations
#     cap_drop: [ALL]      # Keep drop ALL to only allow explicitly added caps
#
# Services Reiring Custom tmpfs Mounts:
# -------------------------------------
# Some services need additional tmpfs mounts beyond /tmp and /var/tmp:
#
#   service-name:
#     <<: *hardening
#     tmpfs:
#       - /tmp:noexec,nosuid,size=64m       # From template
#       - /var/tmp:noexec,nosuid,size=64m   # From template
#       - /app/cache:rw,noexec,nosuid,size=128m  # Add service-specific mount
#
# Common Capabilities Reference:
# ------------------------------
# - NET_BIND_SERVICE - Bind to ports < 1024
# - CHOWN - Change file ownership
# - SETGID - Set group ID
# - SETUID - Set user ID
# - DAC_OVERRIDE - Bypass file read/write/execute permission checks
# - FOWNER - Bypass permission checks on operations with file descriptors
# - KILL - Send signals to processes
# - NET_ADMIN - Network administration (firewall, routing)
# - SYS_ADMIN - Perform system administration tasks (AVOID if possible)
#
# Security Impact:
# ---------------
# - Attack Surface: Reduces container privileges by ~90%
# - Privilege Escalation: Blocks setuid/setgid escalation vectors
# - Rootfs Protection: Read-only prevents malicious code injection
# - Temporary Files: noexec/nosuid prevents executable tmp attacks
# - Compliance: Aligns with CIS Docker Benchmark 1.0.0 sections 5.1-5.3
#
# Applying to Services:
# ---------------------
# This PR adds template anchors only. Follow-up PR will apply to all services.
# See: Task 5 - Apply container hardening to all services
#
# References:
# -----------
# - CIS Docker Benchmark 1.0.0: https://www.cisecurity.org/benchmark/docker
# - Docker Security: https://docs.docker.com/engine/security/
# - Kubernetes Pod Security: https://kubernetes.io/docs/concepts/security/pod-security-standards/
# =============================================================================

# Read-only hardening for stateless services
# Use for: API gateways, proxies, compute services (no local writes)
x-hardening: &hardening
  cap_drop:
    - ALL
  cap_add:
    - NET_BIND_SERVICE
  read_only: true
  security_opt:
    - no-new-privileges:true
  tmpfs:
    - /tmp:noexec,nosuid,size=64m
    - /var/tmp:noexec,nosuid,size=64m

# Read-write hardening for services needing filesystem access
# Use for: Databases, log writers, services with volumes
x-hardening-rw: &hardening-rw
  cap_drop:
    - ALL
  cap_add:
    - NET_BIND_SERVICE
    - CHOWN
    - SETGID
    - SETUID
  security_opt:
    - no-new-privileges:true

# PMOVES.AI production compose project
name: pmoves

services:
  # =============================================================================
  # SUPABASE SELF-HOSTED STACK (2025 Best Practices)
  # =============================================================================
  # Integrated Supabase services - no external CLI dependency
  # All services run on pmoves internal networks for security
  # 2025 Key Naming: PUBLISHABLE_KEY / SECRET_KEY (legacy: ANON_KEY / SERVICE_ROLE_KEY)
  # 2025 JWT: RS256 asymmetric (legacy: HS256 symmetric)
  # =============================================================================

  supabase-db:
    <<: *id008
    image: supabase/postgres:17.6.1.079
    restart: unless-stopped
    environment:
    - POSTGRES_USER=${SUPABASE_DB_USER}
    - POSTGRES_PASSWORD=${SUPABASE_DB_PASSWORD}
    - POSTGRES_DB=${SUPABASE_DB_NAME}
    - POSTGRES_INITDB_ARGS=--encoding=UTF-8
    # PMOVES extensions
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    ports:
    - ${SUPABASE_DB_PORT:-54322}:5432
    volumes:
    - supabase-db-data:/var/lib/postgresql/data
    networks:
    - pmoves_data

  supabase-gotrue:
    <<: *id008
    image: supabase/gotrue:v2.186.0
    restart: unless-stopped
    environment:
    # 2025: Use RS256 for asymmetric JWT (public/private key pair)
    - GOTRUE_SITE_URL=${SUPABASE_SITE_URL}
    - API_EXTERNAL_URL=${SUPABASE_PUBLIC_URL}
    - GOTRUE_API_HOST=0.0.0.0
    - GOTRUE_API_PORT=9999
    # Database connection
    - GOTRUE_DB_DRIVER=postgres
    - GOTRUE_DB_DATABASE_URL=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@supabase-db:5432/${POSTGRES_DB}?sslmode=disable
    # JWT configuration (2025: RS256)
    - GOTRUE_JWT_SECRET=${SUPABASE_JWT_SECRET}
    - GOTRUE_JWT_ALGORITHM=${SUPABASE_JWT_ALGORITHM}
    - GOTRUE_JWT_EXP=${SUPABASE_JWT_EXP}
    # 2025 key naming
    - GOTRUE_JWT_ADMIN_SECRET=${SUPABASE_SECRET_KEY}
    - GOTRUE_JWT_DEFAULT_GROUP_NAME=authenticated
    # Logging
    - GOTRUE_LOG_LEVEL=info
    - GOTRUE_LOG_LEVEL_STACK=info
    # URI Allow list (for VPS deployment)
    - GOTRUE_URI_ALLOW_LIST=${SUPABASE_URI_ALLOW_LIST}
    # PMOVES context
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9999/health"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      supabase-db:
        condition: service_healthy
    ports:
    - ${SUPABASE_GOTRUE_PORT:-9999}:9999
    networks:
    - pmoves_api
    - pmoves_data

  supabase-postgrest:
    <<: *id008
    image: postgrest/postgrest:v12.2.0
    restart: unless-stopped
    environment:
    # Database connection (from env.tier-supabase)
    - PGRST_DB_URI=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@supabase-db:5432/${POSTGRES_DB}
    # JWT secret (must match gotrue)
    - PGRST_JWT_SECRET=${SUPABASE_JWT_SECRET}
    - PGRST_JWT_ALGORITHM=${SUPABASE_JWT_ALGORITHM}
    # 2025 key naming (service role key for admin access)
    - PGRST_JWT_SECRET_IS_BASE64=false
    # API configuration
    - PGRST_SCHEMA=${SUPABASE_SCHEMA}
    - PGRST_ANON_ROLE=${SUPABASE_ANON_ROLE}
    - PGRST_DB_MAX_ROWS=${SUPABASE_MAX_ROWS}
    - PGRST_DB_POOL=${SUPABASE_DB_POOL}
    - PGRST_DB_POOL_TIMEOUT=${SUPABASE_POOL_TIMEOUT}
    # PMOVES context
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    # Note: No healthcheck - postgrest/postgrest image is distroless without shell tools
    depends_on:
      supabase-db:
        condition: service_healthy
    ports:
    - ${SUPABASE_POSTGREST_PORT:-3000}:3000
    networks:
    - pmoves_api
    - pmoves_data

  supabase-kong:
    <<: *id008
    image: kong:3.7.1
    restart: unless-stopped
    environment:
    # Database configuration (Kong uses Postgres for config storage)
    - KONG_DATABASE=postgres
    - KONG_PG_HOST=supabase-db
    - KONG_PG_DATABASE=${POSTGRES_DB}
    - KONG_PG_USER=${POSTGRES_USER}
    - KONG_PG_PASSWORD=${POSTGRES_PASSWORD}
    # Kong configuration
    - KONG_PROXY_ACCESS_LOG=/dev/stdout
    - KONG_ADMIN_ACCESS_LOG=/dev/stdout
    - KONG_PROXY_ERROR_LOG=/dev/stderr
    - KONG_ADMIN_ERROR_LOG=/dev/stderr
    - KONG_PROXY_LISTEN=0.0.0.0:8000
    - KONG_ADMIN_LISTEN=0.0.0.0:8001
    # JWT plugin (2025: RS256 support)
    - KONG_PLUGINS=bundled,jwt
    - KONG_NGINX_PROXY_PROXY_BUFFERS=8 16k
    # PMOVES context
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      supabase-db:
        condition: service_healthy
    ports:
    - ${SUPABASE_KONG_PROXY_PORT:-8000}:8000
    - ${SUPABASE_KONG_ADMIN_PORT:-8001}:8001
    networks:
    - pmoves_api
    - pmoves_data

  supabase-realtime:
    <<: *id008
    image: supabase/realtime:v2.30.26
    restart: unless-stopped
    environment:
    # Database connection
    - DB_HOST=supabase-db
    - DB_PORT=5432
    - DB_NAME=${POSTGRES_DB}
    - DB_USER=${POSTGRES_USER}
    - DB_PASSWORD=${POSTGRES_PASSWORD}
    - DB_SSL=false
    # App configuration
    - APP_NAME=realtime
    - PORT=4000
    - RLIMIT_NOFILE=1048576
    # JWT secret (must match gotrue)
    - JWT_SECRET=${SUPABASE_JWT_SECRET}
    - SECRET_KEY_BASE=${SUPABASE_REALTIME_SECRET}
    # PMOVES context
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    # Healthcheck: Simple HTTP check (Realtime serves HTML on /)
    # Note: Official Supabase uses /api/tenants/{tenant}/health with Bearer token, but that endpoint returns 500 until DB migrations complete
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:4000/ > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 15s
    depends_on:
      supabase-db:
        condition: service_healthy
    ports:
    - ${SUPABASE_REALTIME_PORT:-4000}:4000
    networks:
    - pmoves_api
    - pmoves_data

  supabase-storage:
    <<: *id008
    image: supabase/storage-api:v1.36.2
    restart: unless-stopped
    environment:
    # 2025 key naming
    - ANON_KEY=${SUPABASE_PUBLISHABLE_KEY}
    - SERVICE_KEY=${SUPABASE_SECRET_KEY}
    # JWT secret
    - PGRST_JWT_SECRET=${SUPABASE_JWT_SECRET}
    - PGRST_JWT_ALGORITHM=${SUPABASE_JWT_ALGORITHM}
    # PostgREST connection
    - POSTGREST_URL=http://supabase-postgrest:3000
    # Database connection
    - DATABASE_URL=postgres://postgres:postgres@supabase-db:5432/postgres
    # Storage configuration
    - FILE_SIZE_LIMIT=52428800
    - STORAGE_BACKEND=file
    - FILE_STORAGE_BACKEND_PATH=/var/lib/storage
    - REGION=${SUPABASE_STORAGE_REGION}
    # Global S3 bucket (if using MinIO for actual storage)
    - GLOBAL_S3_BUCKET=${SUPABASE_S3_BUCKET}
    - GLOBAL_S3_ENDPOINT=${MINIO_ENDPOINT}
    - GLOBAL_S3_FORCE_PATH_STYLE=true
    # Tenant mode (single tenant for self-hosted)
    - TENANT_ID=stub
    - TENANTSStub_REGION=${SUPABASE_STORAGE_REGION}
    # PMOVES context
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    # Healthcheck: Use 127.0.0.1 explicitly (localhost resolves to ::1 on IPv6, causing connection refused)
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:5000/status"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 10s
    depends_on:
      supabase-db:
        condition: service_healthy
      supabase-postgrest:
        condition: service_started
    volumes:
    - supabase-storage-data:/var/lib/storage
    ports:
    - ${SUPABASE_STORAGE_PORT:-5000}:5000
    networks:
    - pmoves_api
    - pmoves_data

  supabase-studio:
    <<: *id008
    # Pinned 2025-02-04: Latest stable from Supabase
    image: supabase/studio:2026.02.04-sha-fba1944
    restart: unless-stopped
    environment:
    # PostgREST connection
    - STUDIO_PG_META_URL=http://supabase-postgrest:3000
    # Auth connection
    - SUPABASE_URL=http://supabase-gotrue:9999
    # 2025 key naming
    - SUPABASE_PUBLIC_URL=${SUPABASE_PUBLIC_URL}
    - SUPABASE_ANON_KEY=${SUPABASE_PUBLISHABLE_KEY}
    # PMOVES context
    - DOCKED_MODE=${DOCKED_MODE}
    - PARENT_SYSTEM=${PARENT_SYSTEM}
    - PARENT_VERSION=${PARENT_VERSION}
    # Healthcheck: External check (Next.js 16 binds to container hostname, not localhost)
    # Note: Official Supabase uses node -e fetch but their image has different network config
    # We rely on container being started successfully (logs show "Ready in Xms")
    healthcheck:
      test: ["CMD-SHELL", "node -e 'process.exit(0)' || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    depends_on:
      supabase-postgrest:
        condition: service_started
      supabase-gotrue:
        condition: service_healthy
    ports:
    - ${SUPABASE_STUDIO_PORT:-54323}:3000
    networks:
    - pmoves_api

  # =============================================================================
  # END SUPABASE STACK
  # =============================================================================

  qdrant:
    image: qdrant/qdrant:v1.10.0
    restart: unless-stopped
    ports:
    - ${QDRANT_PORT:-6333}:6333
    networks:
    - pmoves_data
    environment:
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
  meilisearch:
    <<: *id001
    image: getmeili/meilisearch:v1.8
    restart: unless-stopped
    environment:
    - MEILI_ENV=production
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${MEILISEARCH_PORT:-7700}:7700
    networks:
    - pmoves_data
  neo4j:
    image: neo4j:5.22
    env_file:
      - env.tier-data
    restart: unless-stopped
    environment:
    - NEO4J_dbms_security_allow__csv__import__from__file__urls=true
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${NEO4J_HTTP_PORT:-7474}:7474
    - ${NEO4J_BOLT_PORT:-7687}:7687
    volumes:
    - neo4j-data:/data
    - ./neo4j/cypher:/cypher:ro
    networks:
    - pmoves_data
    healthcheck:
      test:
      - CMD-SHELL
      - auth="$$NEO4J_AUTH"; user="$${auth%%/*}"; pass="$${auth#*/}"; /var/lib/neo4j/bin/cypher-shell
        -a bolt://localhost:7687 -u "$$user" -p "$$pass" 'RETURN 1' || exit 1
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 20s
  minio:
    <<: *id001
    # Pinned 2025-02-04: Latest RELEASE tag (MinIO stopped publishing to Docker Hub Oct 2025)
    image: minio/minio:RELEASE.2025-07-23T15-54-02Z
    command: server /data --console-address ":9001"
    environment:
    - MINIO_ROOT_USER=minioadmin
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${MINIO_PORT:-9000}:9000
    - ${MINIO_CONSOLE_PORT:-9001}:9001
    volumes:
    - minio-data:/data
    networks:
    - pmoves_data
    - pmoves_bus
  hi-rag-gateway:
    <<: *id002
    build:
      context: ./services
      dockerfile: hi-rag-gateway/Dockerfile
    restart: unless-stopped
    environment:
    - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    - QDRANT_COLLECTION=${QDRANT_COLLECTION:-pmoves_chunks}
    - SENTENCE_MODEL=${SENTENCE_MODEL:-all-MiniLM-L6-v2}
    - HIRAG_HTTP_PORT=${HIRAG_HTTP_PORT:-8086}
    - GRAPH_BOOST=${GRAPH_BOOST:-0.15}
    - ENTITY_CACHE_TTL=${ENTITY_CACHE_TTL:-3600}
    - ENTITY_CACHE_MAX=${ENTITY_CACHE_MAX:-10000}
    - USE_MEILI=${USE_MEILI:-true}
    - MEILI_URL=${MEILI_URL:-http://meilisearch:7700}
    - NEO4J_URL=${NEO4J_URL:-bolt://neo4j:7687}
    - NEO4J_USER=${NEO4J_USER:-neo4j}
    - NEO4J_PASSWORD=${NEO4J_PASSWORD:-pm_kDhuaogcUc1oOOVeGMNCkQ}
    - NEO4J_DICT_REFRESH_SEC=${NEO4J_DICT_REFRESH_SEC:-300}
    - NEO4J_DICT_LIMIT=${NEO4J_DICT_LIMIT:-1000}
    - TAILSCALE_ONLY=${TAILSCALE_ONLY:-false}
    - TAILSCALE_ADMIN_ONLY=${TAILSCALE_ADMIN_ONLY:-false}
    - TAILSCALE_CIDRS=${TAILSCALE_CIDRS:-}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${HIRAG_V2_HOST_PORT:-8089}:8086
    depends_on:
      qdrant:
        condition: service_started
        required: false
      neo4j:
        condition: service_healthy
        required: false
    networks:
    - pmoves_api
    - pmoves_bus
  retrieval-eval:
    <<: *id003
    build: ./services/retrieval-eval
    restart: unless-stopped
    environment:
    - HIRAG_URL=${HIRAG_URL:-http://hi-rag-gateway-v2:8086}
    - EVAL_HTTP_PORT=${EVAL_HTTP_PORT:-8090}
    depends_on:
    - hi-rag-gateway-v2
    ports:
    - ${RETRIEVAL_EVAL_PORT:-8090}:8090
    volumes:
    - ./services/retrieval-eval:/app:rw
    - ./datasets:/app/data:rw
    profiles:
    - workers
    networks:
    - pmoves_app
    - pmoves_bus
    extra_hosts:
    - host.docker.internal:host-gateway
  presign:
    <<: *id002
    build: ./services/presign
    restart: unless-stopped
    environment:
    - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
    - MINIO_SECURE=false
    - AWS_DEFAULT_REGION=us-east-1
    - ALLOWED_BUCKETS=${ALLOWED_BUCKETS:-assets,outputs}
    ports:
    - ${PRESIGN_PORT:-8088}:8080
    profiles:
    - data
    - orchestration
    networks:
    - pmoves_api
    - pmoves_bus
  render-webhook:
    <<: *id002
    build: ./services/render-webhook
    restart: unless-stopped
    environment:
    - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
    - DEFAULT_NAMESPACE=${INDEXER_NAMESPACE:-pmoves}
    - RENDER_AUTO_APPROVE=${RENDER_AUTO_APPROVE:-false}
    ports:
    - ${RENDER_WEBHOOK_PORT:-8085}:8085
    profiles:
    - orchestration
    - workers
    networks:
    - pmoves_api
    - pmoves_bus
    extra_hosts:
    - host.docker.internal:host-gateway
  model-registry:
    <<: *id002
    build:
      context: ./services/model-registry
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
    - SUPABASE_URL=${MODEL_REGISTRY_SUPABASE_URL:-http://host.docker.internal:54321}
    - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY:-}
    - MODEL_REGISTRY_PORT=${MODEL_REGISTRY_PORT:-8110}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${MODEL_REGISTRY_PORT:-8110}:8110
    profiles:
    - orchestration
    healthcheck:
      test:
      - CMD-SHELL
      - wget --no-verbose --tries=1 --spider http://localhost:8110/healthz || exit 1
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
    - pmoves_api
    - pmoves_bus
    extra_hosts:
    - host.docker.internal:host-gateway
  extract-worker:
    <<: *id003
    build: ./services/extract-worker
    restart: unless-stopped
    environment:
    - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    - QDRANT_COLLECTION=${QDRANT_COLLECTION:-pmoves_chunks}
    - SENTENCE_MODEL=${SENTENCE_MODEL:-all-MiniLM-L6-v2}
    - MEILI_URL=${MEILI_URL:-http://meilisearch:7700}
    - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
    - SUPA_REST_INTERNAL_URL=${SUPA_REST_INTERNAL_URL:-http://host.docker.internal:54321/rest/v1}
    ports:
    - ${EXTRACT_WORKER_PORT:-8083}:8083
    profiles:
    - workers
    - orchestration
    networks:
    - pmoves_app
    - pmoves_bus
    extra_hosts:
    - host.docker.internal:host-gateway
  pdf-ingest:
    <<: *id003
    build:
      context: .
      dockerfile: services/pdf-ingest/Dockerfile
    restart: unless-stopped
    environment:
    # NATS_URL from env.shared/env.tier-worker has credentials: nats://nats:pmoves@nats:4222
    - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
    - MINIO_SECURE=false
    - PDF_DEFAULT_BUCKET=${PDF_DEFAULT_BUCKET:-assets}
    - PDF_DEFAULT_NAMESPACE=${PDF_DEFAULT_NAMESPACE:-pmoves}
    - PDF_MAX_PAGES=${PDF_MAX_PAGES:-0}
    - PDF_INGEST_EXTRACT_URL=${PDF_INGEST_EXTRACT_URL:-http://extract-worker:8083/ingest}
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    depends_on:
      extract-worker:
        condition: service_started
      minio:
        condition: service_started
    ports:
    - ${PDF_INGEST_PORT:-8092}:8092
    profiles:
    - workers
    - orchestration
    networks:
    - pmoves_app
    - pmoves_bus
  langextract:
    <<: *id003
    build:
      context: .
      dockerfile: services/langextract/Dockerfile
    restart: unless-stopped
    ports:
    - ${LANGEXTRACT_PORT:-8084}:8084
    profiles:
    - workers
    - orchestration
    networks:
    - pmoves_app
  notebook-sync:
    <<: *id003
    build: ./services/notebook-sync
    restart: unless-stopped
    environment:
    - OPEN_NOTEBOOK_API_TOKEN=${OPEN_NOTEBOOK_API_TOKEN:-}
    - NOTEBOOK_SYNC_INTERVAL_SECONDS=${NOTEBOOK_SYNC_INTERVAL_SECONDS:-300}
    - NOTEBOOK_SYNC_NAMESPACE=${NOTEBOOK_SYNC_NAMESPACE:-open-notebook}
    - NOTEBOOK_SYNC_DB_PATH=${NOTEBOOK_SYNC_DB_PATH:-/data/notebook_sync.db}
    - LANGEXTRACT_URL=${LANGEXTRACT_URL:-http://langextract:8084}
    - EXTRACT_WORKER_URL=${EXTRACT_WORKER_URL:-http://extract-worker:8083}
    depends_on:
      langextract:
        condition: service_started
      extract-worker:
        condition: service_started
    ports:
    - ${NOTEBOOK_SYNC_PORT:-8095}:8095
    profiles:
    - workers
    - orchestration
    volumes:
    - notebook-sync-data:/data
    networks:
    - pmoves_app
    - pmoves_bus
  ffmpeg-whisper:
    <<: *id004
    build:
      context: ..
      dockerfile: pmoves/services/ffmpeg-whisper/Dockerfile
    restart: unless-stopped
    environment:
    - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
    - MINIO_SECURE=${MINIO_SECURE:-false}
    - USE_CUDA=${USE_CUDA:-true}
    - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    - FFW_PROVIDER=${FFW_PROVIDER:-faster-whisper}
    - WHISPER_MODEL=${WHISPER_MODEL:-small}
    - WHISPER_LANGUAGE=${WHISPER_LANGUAGE:-en}
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities:
            - compute
            - utility
            count: ${GPU_COUNT:-all}
    ports:
    - ${FFMPEG_WHISPER_PORT:-8078}:8078
    profiles:
    - workers
    - orchestration
    - agents
    networks:
    - pmoves_app
    - pmoves_bus
  media-video:
    <<: *id004
    build: ./services/media-video
    restart: unless-stopped
    environment:
    - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
    - MINIO_SECURE=${MINIO_SECURE:-false}
    - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    - YOLO_MODEL=${YOLO_MODEL:-yolov8n.pt}
    - YOLO_CONFIDENCE=${YOLO_CONFIDENCE:-0.25}
    - FRAME_SAMPLE_RATE=${FRAME_SAMPLE_RATE:-5}
    deploy:
      resources:
        reservations:
          devices:
          - capabilities:
            - gpu
            count: ${GPU_COUNT:-all}
    ports:
    - ${MEDIA_VIDEO_PORT:-8079}:8079
    profiles:
    - workers
    - orchestration
    networks:
    - pmoves_app
    - pmoves_bus
  media-audio:
    <<: *id004
    build: ./services/media-audio
    restart: unless-stopped
    environment:
    - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
    - MINIO_SECURE=${MINIO_SECURE:-false}
    - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    - EMOTION_MODEL=${EMOTION_MODEL:-superb/hubert-large-superb-er}
    deploy:
      resources:
        reservations:
          devices:
          - capabilities:
            - gpu
            count: ${GPU_COUNT:-all}
    ports:
    - ${MEDIA_AUDIO_PORT:-8082}:8082
    profiles:
    - workers
    - orchestration
    networks:
    - pmoves_app
    - pmoves_bus
  pmoves-yt:
    <<: *id004
    image: ${PMOVES_YT_IMAGE:-}
    build:
      context: ./services/pmoves-yt
      args:
      - YTDLP_VERSION=${YTDLP_VERSION:-}
    restart: unless-stopped
    environment:
    # NATS_URL from env.tier-media has credentials: nats://nats:pmoves@nats:4222
    - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
    - MINIO_SECURE=${MINIO_SECURE:-false}
    - YT_BUCKET=${YT_BUCKET:-assets}
    - YT_OUTPUT_BUCKET=${YT_OUTPUT_BUCKET:-outputs}
    - INDEXER_NAMESPACE=${INDEXER_NAMESPACE:-pmoves}
    - SUPA_REST_URL=${SUPA_REST_INTERNAL_URL:-${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}}
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    - HIRAG_URL=${HIRAG_URL:-http://hi-rag-gateway-v2:8086}
    - YT_PLAYER_CLIENT=${YT_PLAYER_CLIENT:-web_safari}
    - YT_USER_AGENT=${YT_USER_AGENT:-Mozilla/5.0 (Macintosh; Intel Mac OS X 14_6)
      AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.6 Safari/605.1.15}
    - YT_COOKIES=${YT_COOKIES:-/app/config/cookies/darkxside.youtube.cookies.txt}
    - BGUTIL_HTTP_BASE_URL=${BGUTIL_HTTP_BASE_URL:-http://bgutil-pot-provider:4416}
    - BGUTIL_DISABLE_INNERTUBE=${BGUTIL_DISABLE_INNERTUBE:-1}
    - CHANNEL_MONITOR_STATUS_URL=${CHANNEL_MONITOR_STATUS_URL:-http://channel-monitor:8097/api/monitor/status}
    - YT_TRANSCRIPT_PROVIDER=${YT_TRANSCRIPT_PROVIDER:-faster-whisper}
    - YT_WHISPER_MODEL=${YT_WHISPER_MODEL:-small}
    - YT_TRANSCRIPT_DIARIZE=${YT_TRANSCRIPT_DIARIZE:-false}
    - YT_CHANNEL_CHECK_INTERVAL=${YT_CHANNEL_CHECK_INTERVAL:-3600}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    volumes:
    - ./config:/app/config
    depends_on:
      minio:
        condition: service_started
    ports:
    - ${PMOVES_YT_PORT:-8077}:8077
    networks:
    - pmoves_app
    - pmoves_bus
    - pmoves_external  # Required for YouTube API access
  bgutil-pot-provider:
    image: brainicism/bgutil-ytdlp-pot-provider:1.2.2
    restart: unless-stopped
    environment:
    - PORT=4416
    depends_on:
    - minio
    profiles:
    - orchestration
    - yt
    networks:
    - pmoves_app
    - pmoves_bus
    - pmoves_external  # Required for YouTube processing
  channel-monitor:
    <<: *id005
    build: ./services/channel-monitor
    restart: unless-stopped
    environment:
    - CHANNEL_MONITOR_CONFIG_PATH=${CHANNEL_MONITOR_CONFIG_PATH:-/app/config/channel_monitor.json}
    - CHANNEL_MONITOR_QUEUE_URL=${CHANNEL_MONITOR_QUEUE_URL:-http://pmoves-yt:8077/yt/ingest}
    - CHANNEL_MONITOR_NAMESPACE=${CHANNEL_MONITOR_NAMESPACE:-pmoves}
    # Database URL - points to Supabase DB (note: supabase-db runs on pmoves_data network)
    - CHANNEL_MONITOR_DATABASE_URL=${CHANNEL_MONITOR_DATABASE_URL:-postgresql://postgres:postgres@supabase-db:5432/postgres}
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    volumes:
    - ./config:/app/config
    depends_on:
      pmoves-yt:
        condition: service_started
    ports:
    - ${CHANNEL_MONITOR_PORT:-8097}:8097
    networks:
    - pmoves_app
    - pmoves_bus
    - pmoves_data
    - pmoves_external  # Required for YouTube API access
  hi-rag-gateway-v2:
    <<: *id002
    build:
      context: .
      dockerfile: services/hi-rag-gateway-v2/Dockerfile
    restart: unless-stopped
    environment:
    - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    - QDRANT_COLLECTION=${QDRANT_COLLECTION:-pmoves_chunks}
    - SENTENCE_MODEL=${SENTENCE_MODEL:-all-MiniLM-L6-v2}
    - INDEXER_NAMESPACE=${INDEXER_NAMESPACE:-pmoves}
    - ALPHA=${ALPHA:-0.7}
    - RERANK_ENABLE=${RERANK_ENABLE:-true}
    - RERANK_MODEL=${RERANK_MODEL:-BAAI/bge-reranker-base}
    - RERANK_TOPN=${RERANK_TOPN:-50}
    - RERANK_K=${RERANK_K:-10}
    - RERANK_FUSION=${RERANK_FUSION:-mul}
    - USE_MEILI=true
    - MEILI_URL=${MEILI_URL:-http://meilisearch:7700}
    - NEO4J_URL=${NEO4J_URL:-bolt://neo4j:7687}
    - NEO4J_USER=${NEO4J_USER:-neo4j}
    - NEO4J_PASSWORD=${NEO4J_PASSWORD:-pm_kDhuaogcUc1oOOVeGMNCkQ}
    - USE_OLLAMA_EMBED=${USE_OLLAMA_EMBED:-false}
    - OLLAMA_URL=${OLLAMA_URL:-http://pmoves-ollama:11434}
    - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL:-embeddinggemma:300m}
    - TENSORZERO_BASE_URL=${TENSORZERO_BASE_URL:-http://tensorzero-gateway:3000}
    - TENSORZERO_EMBED_MODEL=${TENSORZERO_EMBED_MODEL:-tensorzero::embedding_model_name::gemma_embed_local}
    - GRAPH_BOOST=${GRAPH_BOOST:-0.15}
    - ENTITY_CACHE_TTL=${ENTITY_CACHE_TTL:-60}
    - ENTITY_CACHE_MAX=${ENTITY_CACHE_MAX:-1000}
    - NEO4J_DICT_REFRESH_SEC=${NEO4J_DICT_REFRESH_SEC:-60}
    - NEO4J_DICT_LIMIT=${NEO4J_DICT_LIMIT:-50000}
    - TAILSCALE_ONLY=${TAILSCALE_ONLY:-false}
    - TAILSCALE_CIDRS=${TAILSCALE_CIDRS:-100.64.0.0/10}
    - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
    - SUPABASE_REALTIME_URL=${SUPABASE_REALTIME_URL:-ws://host.docker.internal:54321/realtime/v1}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    extra_hosts:
    - host.docker.internal:host-gateway
    ports:
    - ${HIRAG_V2_HOST_PORT:-8086}:8086
    depends_on:
      qdrant:
        condition: service_started
      neo4j:
        condition: service_healthy
    networks:
    - pmoves_api
    - pmoves_bus
    - pmoves_external  # Required for reranker API calls
  hi-rag-gateway-gpu:
    <<: *id002
    build:
      context: ./services
      dockerfile: hi-rag-gateway/Dockerfile
      args:
      - TORCH_CUDA_VERSION=${TORCH_CUDA_VERSION:-cu128}
      - TORCH_SKIP_CUDA=0
    restart: unless-stopped
    environment:
    - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    - QDRANT_COLLECTION=${QDRANT_COLLECTION:-pmoves_chunks}
    - SENTENCE_MODEL=${SENTENCE_MODEL:-all-MiniLM-L6-v2}
    - HIRAG_HTTP_PORT=${HIRAG_HTTP_PORT:-8086}
    - GRAPH_BOOST=${GRAPH_BOOST:-0.15}
    - ENTITY_CACHE_TTL=${ENTITY_CACHE_TTL:-3600}
    - ENTITY_CACHE_MAX=${ENTITY_CACHE_MAX:-10000}
    - USE_MEILI=${USE_MEILI:-true}
    - MEILI_URL=${MEILI_URL:-http://meilisearch:7700}
    - NEO4J_URL=${NEO4J_URL:-bolt://neo4j:7687}
    - NEO4J_USER=${NEO4J_USER:-neo4j}
    - NEO4J_PASSWORD=${NEO4J_PASSWORD:-pm_kDhuaogcUc1oOOVeGMNCkQ}
    - NEO4J_DICT_REFRESH_SEC=${NEO4J_DICT_REFRESH_SEC:-300}
    - NEO4J_DICT_LIMIT=${NEO4J_DICT_LIMIT:-1000}
    - TAILSCALE_ONLY=${TAILSCALE_ONLY:-false}
    - TAILSCALE_ADMIN_ONLY=${TAILSCALE_ADMIN_ONLY:-false}
    - TAILSCALE_CIDRS=${TAILSCALE_CIDRS:-}
    - RERANK_ENABLE=${RERANK_ENABLE:-true}
    - RERANK_MODEL=${RERANK_MODEL:-BAAI/bge-reranker-base}
    - RERANK_TOPN=${RERANK_TOPN:-50}
    - RERANK_K=${RERANK_K:-10}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    deploy:
      resources:
        reservations:
          devices:
          - capabilities:
            - gpu
            count: ${GPU_COUNT:-all}
    ports:
    - ${HIRAG_V2_GPU_HOST_PORT:-8090}:8086
    depends_on:
      qdrant:
        condition: service_started
        required: false
      neo4j:
        condition: service_healthy
        required: false
    networks:
    - pmoves_api
    - pmoves_bus
  hi-rag-gateway-v2-gpu:
    <<: *id002
    build:
      context: .
      dockerfile: services/hi-rag-gateway-v2/Dockerfile.gpu
      args:
        TORCH_CUDA: ${TORCH_CUDA_VERSION:-cu128}
        TORCH_VERSION: ${TORCH_VERSION:-2.9.0}
        TORCHAUDIO_VERSION: ${TORCHAUDIO_VERSION:-2.9.0}
    runtime: nvidia
    restart: unless-stopped
    command:
    - uvicorn
    - app:app
    - --host
    - 0.0.0.0
    - --port
    - '8086'
    environment:
    - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    - QDRANT_COLLECTION=${QDRANT_COLLECTION:-pmoves_chunks}
    - SENTENCE_MODEL=${SENTENCE_MODEL:-all-MiniLM-L6-v2}
    - INDEXER_NAMESPACE=${INDEXER_NAMESPACE:-pmoves}
    - ALPHA=${ALPHA:-0.7}
    - RERANK_ENABLE=${RERANK_ENABLE:-true}
    - RERANK_MODEL=Qwen/Qwen3-Reranker-4B
    - RERANK_TOPN=${RERANK_TOPN:-50}
    - RERANK_K=${RERANK_K:-10}
    - RERANK_FUSION=${RERANK_FUSION:-mul}
    - USE_MEILI=${USE_MEILI:-true}
    - MEILI_URL=${MEILI_URL:-http://meilisearch:7700}
    - GRAPH_BOOST=${GRAPH_BOOST:-0.15}
    - ENTITY_CACHE_TTL=${ENTITY_CACHE_TTL:-60}
    - ENTITY_CACHE_MAX=${ENTITY_CACHE_MAX:-1000}
    - NEO4J_DICT_REFRESH_SEC=${NEO4J_DICT_REFRESH_SEC:-60}
    - NEO4J_DICT_LIMIT=${NEO4J_DICT_LIMIT:-50000}
    - CHIT_DECODE_TEXT=${CHIT_DECODE_TEXT:-true}
    - CHIT_DECODE_IMAGE=${CHIT_DECODE_IMAGE:-true}
    - CHIT_DECODE_AUDIO=${CHIT_DECODE_AUDIO:-true}
    - CHIT_PERSIST_DB=${CHIT_PERSIST_DB:-false}
    - PGHOST=${PGHOST:-postgres}
    - PGPORT=${PGPORT:-5432}
    - PGUSER=${POSTGRES_USER:-pmoves}
    - PGPASSWORD=${POSTGRES_PASSWORD:-pmoves}
    - PGDATABASE=${POSTGRES_DB:-pmoves}
    - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
    - SUPABASE_REALTIME_URL=${SUPABASE_REALTIME_URL:-ws://host.docker.internal:54321/realtime/v1}
    - OLLAMA_URL=${OLLAMA_URL:-http://pmoves-ollama:11434}
    - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL:-embeddinggemma:300m}
    - TENSORZERO_BASE_URL=${TENSORZERO_BASE_URL:-http://tensorzero-gateway:3000}
    - TENSORZERO_API_KEY=${TENSORZERO_API_KEY:-}
    - TENSORZERO_EMBED_MODEL=${TENSORZERO_EMBED_MODEL:-tensorzero::embedding_model_name::gemma_embed_local}
    - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    gpus: all
    deploy:
      resources:
        reservations:
          devices:
          - capabilities:
            - gpu
            count: ${GPU_COUNT:-all}
    ports:
    - ${HIRAG_V2_GPU_HOST_PORT:-8087}:8086
    depends_on:
      qdrant:
        condition: service_started
        required: false
      neo4j:
        condition: service_healthy
        required: false
    networks:
    - pmoves_api
    - pmoves_bus
    extra_hosts:
    - host.docker.internal:host-gateway
  nats:
    <<: *id001
    # Pinned 2025-02-04: Latest stable 2.11.x alpine version
    image: nats:2.11.8-alpine
    command:
    - -js
    - -m
    - '8222'
    - --user
    - nats
    - --pass
    - pmoves
    restart: unless-stopped
    ports:
    - ${NATS_PORT:-4222}:4222
    - ${NATS_MONITORING_PORT:-9223}:4223
    networks:
    - pmoves_bus
    environment:
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
  agent-zero:
    <<: *id005
    build:
      context: .
      dockerfile: ./services/agent-zero/Dockerfile
    restart: unless-stopped
    environment:
    - PORT=8080
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - AGENT_ZERO_API_BASE=${AGENT_ZERO_API_BASE:-http://127.0.0.1:80}
    - AGENT_ZERO_CAPTURE_OUTPUT=${AGENT_ZERO_CAPTURE_OUTPUT:-true}
    - AGENT_ZERO_EXTRA_ARGS=${AGENT_ZERO_EXTRA_ARGS:---port=80 --host=0.0.0.0}
    - AGENTZERO_JETSTREAM=${AGENTZERO_JETSTREAM:-true}
    - AGENTZERO_JS_UNAVAILABLE_THRESHOLD=${AGENTZERO_JS_UNAVAILABLE_THRESHOLD:-1}
    - TENSORZERO_URL=${TENSORZERO_URL:-http://tensorzero-gateway:3000}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    depends_on:
    - nats
    ports:
    - ${AGENT_ZERO_PORT:-8080}:8080
    - ${AGENT_ZERO_PORT:-8081}:80
    volumes:
    - ${AGENT_ZERO_MEMORY_DIR:-./data/agent-zero/memory}:/a0/memory
    - ${AGENT_ZERO_KNOWLEDGE_DIR:-./data/agent-zero/knowledge}:/a0/knowledge
    - ${AGENT_ZERO_INSTRUMENTS_DIR:-./data/agent-zero/instruments}:/a0/instruments
    - ${AGENT_ZERO_LOG_DIR:-./data/agent-zero/logs}:/a0/logs
    - ${AGENT_ZERO_RUNTIME_DIR:-./data/agent-zero/runtime}:/a0/runtime
    networks:
    - pmoves_app
    - pmoves_bus
    - pmoves_external  # Required for LLM provider APIs
  archon:
    <<: *id005
    build:
      context: .
      dockerfile: ./services/archon/Dockerfile
      args:
      - ARCHON_GIT_REMOTE=${ARCHON_GIT_REMOTE:-https://github.com/POWERFULMOVES/PMOVES-Archon.git}
      - ARCHON_GIT_REF=${ARCHON_GIT_REF:-main}
    restart: unless-stopped
    environment:
      # SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY from env.tier-agent
      # NATS_URL from env.shared/env.tier-agent has credentials: nats://nats:pmoves@nats:4222
      - PORT=8091
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8091}
      - ARCHON_SERVER_URL=${ARCHON_SERVER_URL:-http://localhost:8091}
      - ARCHON_MCP_PORT=${ARCHON_MCP_PORT:-8051}
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
      - ARCHON_VENDOR_FORCE_PLACEHOLDER=${ARCHON_VENDOR_FORCE_PLACEHOLDER:-0}
      - ARCHON_SUPABASE_BASE_URL=${ARCHON_SUPABASE_BASE_URL:-http://supabase-kong:8000}
      - NATS_URL=${NATS_URL:-nats://nats:4222}
      - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
    depends_on:
      nats:
        condition: service_started
    command:
    - python
    - -c
    - import uvicorn; from services.archon.main import app; uvicorn.run(app, host='0.0.0.0',
      port=8091, log_level='info')
    ports:
    - ${ARCHON_PORT:-8091}:8091
    - ${ARCHON_PORT:-8051}:8051
    - ${ARCHON_PORT:-8052}:8052
    networks:
      pmoves_app:
        aliases:
        - archon-server
      pmoves_api:
      pmoves_bus:
    extra_hosts:
    - host.docker.internal:host-gateway
    healthcheck:
      test:
      - CMD-SHELL
      - python -c "import urllib.request,sys; sys.exit(0) if urllib.request.urlopen('http://localhost:8091/healthz').getcode()==200
        else sys.exit(1)"
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 15s
  mesh-agent:
    <<: *id005
    build: ./services/mesh-agent
    restart: unless-stopped
    environment:
    # NATS_URL from env.shared/env.tier-agent has credentials: nats://nats:pmoves@nats:4222
      - HIRAG_URL=${HIRAG_URL:-http://hi-rag-gateway-v2-gpu:8086}
      - ANNOUNCE_SEC=${ANNOUNCE_SEC:-15}
    depends_on: [nats]
    profiles: ["agents"]
    networks: [pmoves_app, pmoves_bus]

  # Tier: agent (BoTZ Gateway - Bot management with Geometry BUS integration)
  botz-gateway:
    build: ./services/botz-gateway
    restart: unless-stopped
    <<: *id005
    environment:
      - NATS_URL=${NATS_URL:-nats://nats:4222}
      - SUPABASE_URL=${SUPABASE_URL:-http://host.docker.internal:54321}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_KEY}
      - TENSORZERO_URL=${TENSORZERO_URL:-http://tensorzero-gateway:3000}
      - BOTZ_HEARTBEAT_INTERVAL=${BOTZ_HEARTBEAT_INTERVAL:-30}
      - BOTZ_STALE_THRESHOLD=${BOTZ_STALE_THRESHOLD:-5}
    depends_on:
      nats:
        condition: service_started
    ports: ["8054:8054"]
    profiles: ["agents", "botz"]
    networks: [pmoves_app, pmoves_bus, pmoves_api, pmoves_monitoring]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8054/healthz', timeout=5)"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 15s

  # Tier: agent (A2UI NATS bridge - geometry bus integration)
  a2ui-nats-bridge:
    <<: *id005
    build: ./services/a2ui-nats-bridge
    image: ${A2UI_BRIDGE_IMAGE:-ghcr.io/powerfulmoves/pmoves-a2ui-nats-bridge:pmoves-latest}
    container_name: pmoves-a2ui-nats-bridge
    hostname: a2ui-nats-bridge
    restart: unless-stopped
    environment:
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.shared/env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - A2UI_RENDER_SUBJECT=${A2UI_RENDER_SUBJECT:-a2ui.render.v1}
    - GEOMETRY_WILDCARD=${GEOMETRY_WILDCARD:-geometry.>}
    - PORT=9224
    ports:
    - 9224:9224
    depends_on:
    - nats
    profiles:
    - agents
    networks:
    - pmoves_app
    - pmoves_bus
    healthcheck:
      test:
      - CMD
      - python3
      - -c
      - import urllib.request; urllib.request.urlopen('http://localhost:9224/healthz',
        timeout=5)
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    cap_drop:
    - ALL
    security_opt:
    - no-new-privileges:true
  deepresearch:
    <<: *id005
    build:
      context: ./services
      dockerfile: deepresearch/Dockerfile
    image: ${DEEPRESEARCH_IMAGE:-}
    restart: unless-stopped
    environment:
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - DEEPRESEARCH_MODE=${DEEPRESEARCH_MODE:-tensorzero}
    - DEEPRESEARCH_TIMEOUT=${DEEPRESEARCH_TIMEOUT:-600}
    - DEEPRESEARCH_TENSORZERO_BASE_URL=${DEEPRESEARCH_TENSORZERO_BASE_URL:-http://tensorzero-gateway:3000}
    - DEEPRESEARCH_API_BASE=${DEEPRESEARCH_API_BASE:-http://deepresearch-local:8080}
    - DEEPRESEARCH_PLANNING_ENDPOINT=${DEEPRESEARCH_PLANNING_ENDPOINT:-/api/research}
    - DEEPRESEARCH_OPENROUTER_MODEL=${DEEPRESEARCH_OPENROUTER_MODEL:-tongyi-deepresearch}
    - DEEPRESEARCH_OPENROUTER_API_BASE=${DEEPRESEARCH_OPENROUTER_API_BASE:-https://openrouter.ai/api}
    - DEEPRESEARCH_NOTEBOOK_EMBED=${DEEPRESEARCH_NOTEBOOK_EMBED:-true}
    - DEEPRESEARCH_NOTEBOOK_ASYNC=${DEEPRESEARCH_NOTEBOOK_ASYNC:-true}
    - DEEPRESEARCH_HEALTH_PORT=${DEEPRESEARCH_HEALTH_PORT:-8098}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    depends_on:
    - nats
    ports:
    - ${DEEPRESEARCH_PORT:-8098}:8098
    volumes:
    - ./contracts:/app/contracts:ro
    networks:
    - pmoves_app
    - pmoves_bus
  supaserch:
    <<: *id005
    build:
      context: ./services
      dockerfile: supaserch/Dockerfile
    image: ${SUPASERCH_IMAGE:-}
    restart: unless-stopped
    environment:
    - SUPASERCH_PORT=${SUPASERCH_PORT:-8099}
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - SUPASERCH_PORT=${SUPASERCH_PORT:-8099}
    - HIRAG_URL=${HIRAG_URL:-http://hi-rag-gateway-v2:8086}
    - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
    - TENSORZERO_URL=${TENSORZERO_URL:-http://tensorzero-gateway:3000}
    ports:
    - ${SUPASERCH_PORT:-8099}:8099
    networks:
    - pmoves_app
    - pmoves_bus
  nats-echo-req:
    <<: *id005
    build:
      context: ./services
      dockerfile: nats-echo/Dockerfile
    restart: unless-stopped
    environment:
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - NATS_ECHO_SUBJECT=research.deepresearch.request.v1
    depends_on:
    - nats
    profiles:
    - agents
    - diag
    networks:
    - pmoves_bus
  nats-echo-res:
    <<: *id005
    build:
      context: ./services
      dockerfile: nats-echo/Dockerfile
    restart: unless-stopped
    environment:
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - NATS_ECHO_SUBJECT=research.deepresearch.result.v1
    depends_on:
    - nats
    profiles:
    - agents
    - diag
    networks:
    - pmoves_bus
  publisher-discord:
    <<: *id005
    build:
      context: .
      dockerfile: ./services/publisher-discord/Dockerfile
    restart: unless-stopped
    environment:
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.shared/env.tier-agent has credentials: nats://nats:pmoves@nats:4222
    - DISCORD_SUBJECTS=${DISCORD_SUBJECTS:-ingest.file.added.v1,ingest.transcript.ready.v1,ingest.summary.ready.v1,ingest.chapters.ready.v1}
    depends_on:
    - nats
    ports:
    - 8094:8092
    profiles:
    - orchestration
    - agents
    networks:
    - pmoves_app
    - pmoves_bus
  jellyfin-bridge:
    <<: *id005
    build: ./services/jellyfin-bridge
    restart: unless-stopped
    environment:
    - JELLYFIN_URL=${JELLYFIN_INTERNAL_URL:-http://cataclysm-jellyfin:8096}
    - SUPA_REST_URL=${SUPA_REST_INTERNAL_URL:-${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}}
    ports:
    - 8093:8093
    profiles:
    - orchestration
    networks:
    - pmoves_app
    - pmoves_bus
  pmoves-ollama:
    <<: *id006
    image: ${PMOVES_OLLAMA_IMAGE:-ollama/ollama:0.12.6}
    restart: unless-stopped
    environment:
    - OLLAMA_HOST=0.0.0.0:11434
    - OLLAMA_MODELS=/root/.ollama/models
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    volumes:
    - pmoves-ollama-models:/root/.ollama/models
    networks:
    - pmoves_api
  tensorzero-clickhouse:
    <<: *id006
    image: clickhouse/clickhouse-server:24.12-alpine
    restart: unless-stopped
    environment:
    - CLICKHOUSE_USER=tensorzero
    - CLICKHOUSE_PASSWORD=tensorzero
    - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${TENSORZERO_CLICKHOUSE_PORT:-8123}:8123
    volumes:
    - tensorzero-clickhouse-data:/var/lib/clickhouse
    healthcheck:
      test:
      - CMD-SHELL
      - wget --spider --tries 1 http://$${CLICKHOUSE_USER:-default}:$${CLICKHOUSE_PASSWORD:-}@$${HOSTNAME:-localhost}:8123/ping
      start_period: 30s
      interval: 5s
      timeout: 2s
      retries: 5
    networks:
    - pmoves_data
  tensorzero-gateway:
    <<: *id006
    # Pinned 2025-02-04: Latest stable from TensorZero
    image: tensorzero/gateway:2026.1.8
    restart: unless-stopped
    command:
    - --config-file
    - /app/config/tensorzero.toml
    environment:
    - TENSORZERO_CLICKHOUSE_URL=${TENSORZERO_CLICKHOUSE_URL:-http://tensorzero:tensorzero@tensorzero-clickhouse:8123/default}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    volumes:
    - ./tensorzero/config:/app/config:ro
    depends_on:
      tensorzero-clickhouse:
        condition: service_healthy
    ports:
    - ${TENSORZERO_PORT:-3030}:3000
    networks:
    - pmoves_api
    - pmoves_bus
    - pmoves_data
    extra_hosts:
    - host.docker.internal:host-gateway
  tensorzero-ui:
    <<: *id006
    # Pinned 2025-02-04: Latest stable from TensorZero (matches gateway version)
    image: tensorzero/ui:2026.1.8
    restart: unless-stopped
    environment:
    - TENSORZERO_GATEWAY_URL=${TENSORZERO_GATEWAY_URL:-http://tensorzero-gateway:3000}
    - TENSORZERO_CLICKHOUSE_URL=${TENSORZERO_CLICKHOUSE_URL:-http://tensorzero:tensorzero@tensorzero-clickhouse:8123/default}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    volumes:
    - ./tensorzero/config:/app/config:ro
    depends_on:
      tensorzero-clickhouse:
        condition: service_healthy
      tensorzero-gateway:
        condition: service_started
    ports:
    - ${TENSORZERO_UI_PORT:-4000}:4000
    profiles:
    - tensorzero
    networks:
    - pmoves_app
    - pmoves_data
  gpu-orchestrator:
    env_file:
    - env.shared
    - env.tier-llm
    - env.tier-api
    build:
      context: ./services/gpu-orchestrator
      dockerfile: Dockerfile
    image: ${GPU_ORCHESTRATOR_IMAGE:-ghcr.io/powerfulmoves/pmoves-gpu-orchestrator:latest}
    restart: unless-stopped
    environment:
    - NVIDIA_VISIBLE_DEVICES=all
    - GPU_MODELS_CONFIG=/config/gpu-models.yaml
    - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://pmoves-ollama:11434}
    - VLLM_BASE_URL=${VLLM_BASE_URL:-http://pmoves-vllm:8000}
    - TTS_BASE_URL=${TTS_BASE_URL:-http://ultimate-tts-studio:7861}
    - GPU_ORCHESTRATOR_MAX_MODELS=${GPU_ORCHESTRATOR_MAX_MODELS:-3}
    - GPU_ORCHESTRATOR_VRAM_THRESHOLD=${GPU_ORCHESTRATOR_VRAM_THRESHOLD:-0.9}
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro
    - ./config/gpu-models.yaml:/config/gpu-models.yaml:ro
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities:
            - gpu
    profiles:
    - gpu
    networks:
    - pmoves_api
    - pmoves_bus
    - pmoves_monitoring
    ports:
    - 8100:8100
    - 8200:8200
    depends_on:
      nats:
        condition: service_started
        required: false
  evo-controller:
    <<: *id005
    build:
      context: ./services/evo-controller
      dockerfile: Dockerfile
    image: ${EVO_CONTROLLER_IMAGE:-ghcr.io/powerfulmoves/pmoves-evo-controller:latest}
    restart: unless-stopped
    environment:
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
      - PORT=8113
      - SUPA_REST_URL=${SUPA_REST_URL:-http://host.docker.internal:54321/rest/v1}
      - EVOSWARM_POLL_SECONDS=${EVOSWARM_POLL_SECONDS:-300}
      - EVOSWARM_SAMPLE_LIMIT=${EVOSWARM_SAMPLE_LIMIT:-25}
      - EVOSWARM_NAMESPACE=${EVOSWARM_NAMESPACE:-}
      - NATS_URL=${NATS_URL:-nats://nats:4222}
    ports: ["8113:8113"]
    profiles: ["orchestration"]
    networks: [pmoves_app, pmoves_bus]

  # Ultimate TTS Studio - Multi-engine TTS with 7 engines (Gradio UI)
  ultimate-tts-studio:
    build:
      context: ./docker/ultimate-tts-studio
      dockerfile: Dockerfile
    image: ${ULTIMATE_TTS_IMAGE:-ghcr.io/powerfulmoves/pmoves-ultimate-tts-studio:pmoves-latest}
    restart: unless-stopped
    <<: *id004
    environment:
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=7861
      - GRADIO_MCP_SERVER=true
      # WSL2/CUDA compatibility settings
      - CUDA_FORCE_PTX_JIT=1
      - CUDA_DEVICE_ORDER=PCI_BUS_ID
      - TORCH_CUDA_ARCH_LIST=5.0;5.2;6.0;6.1;7.0;7.5;8.0;8.6;9.0
      - TORCH_CUDNN_V8_API_ENABLED=1
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    ports: ["7861:7861"]
    profiles: ["gpu", "tts"]
    networks: [pmoves_app, pmoves_monitoring]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:7861/', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Flute Gateway - Multimodal voice communication layer (TTS/STT)
  flute-gateway:
    <<: *id004
    build:
      context: ./services/flute-gateway
      dockerfile: Dockerfile
    image: ${FLUTE_GATEWAY_IMAGE:-ghcr.io/powerfulmoves/pmoves-flute-gateway:latest}
    restart: unless-stopped
    environment:
    # NATS_URL from env.shared/env.tier-media has credentials: nats://nats:pmoves@nats:4222
      - PORT=8055
      - NATS_URL=${NATS_URL:-nats://nats:4222}
      - SUPABASE_URL=${SUPABASE_URL:-http://host.docker.internal:54321}
      - DEFAULT_VOICE_PROVIDER=${DEFAULT_VOICE_PROVIDER:-vibevoice}
      - FLUTE_API_KEY=${FLUTE_API_KEY:-}
    ports: ["8055:8055", "8056:8056"]
    profiles: ["orchestration", "media"]
    networks: [pmoves_app, pmoves_bus]

  # Tier: agent (Tokenism Simulator - CHIT/geometry bus simulation service)
  tokenism-simulator:
    build:
      context: ./services/tokenism-simulator
      dockerfile: Dockerfile
    image: ${TOKENISM_IMAGE:-ghcr.io/powerfulmoves/pmoves-tokenism:pmoves-latest}
    restart: unless-stopped
    <<: *id005
    environment:
    # NATS_URL from env.shared/env.tier-agent has credentials: nats://nats:pmoves@nats:4222
      - TOKENISM_HOST=${TOKENISM_HOST:-0.0.0.0}
      - TOKENISM_PORT=${TOKENISM_PORT:-8100}
      - FLASK_ENV=${FLASK_ENV:-production}
      - SECRET_KEY=${SECRET_KEY:-pmoves-tokenism-secret}
      - NATS_URL=${NATS_URL:-nats://nats:4222}
      - NATS_CLIENT_NAME=tokenism-simulator
      - NATS_JETSTREAM=${NATS_JETSTREAM:-true}
      - TENSORZERO_URL=${TENSORZERO_URL:-http://tensorzero-gateway:3000}
      - TENSORZERO_MODEL=${TENSORZERO_MODEL:-claude-sonnet-4-5}
      - SUPABASE_URL=${SUPABASE_URL:-http://host.docker.internal:54321}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - AGENTZERO_URL=${AGENTZERO_URL:-http://agent-zero:8080}
      - AGENTZERO_MCP_ENABLED=${AGENTZERO_MCP_ENABLED:-true}
      - CHIT_ENABLED=${CHIT_ENABLED:-true}
      - GEOMETRY_BUS_URL=${GEOMETRY_BUS_URL:-nats://nats:4222}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports: ["${TOKENISM_HOST_PORT:-8103}:8100"]
    profiles: ["agents", "orchestration", "botz"]
    depends_on: [nats]
    networks: [pmoves_app, pmoves_api, pmoves_bus, pmoves_monitoring]
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8100/healthz', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # PMOVES Tokenism UI - Interactive dashboard for token economy simulation
  tokenism-ui:
    build:
      context: ./PMOVES-ToKenism-Multi/pmoves-nextjs
      dockerfile: Dockerfile
    image: ${TOKENISM_UI_IMAGE:-ghcr.io/powerfulmoves/pmoves-tokenism-ui:pmoves-latest}
    restart: unless-stopped
    <<: *id007
    environment:
      - NEXT_PUBLIC_TOKENISM_URL=${TOKENISM_UI_API_URL:-http://tokenism-simulator:8100}
      - NODE_ENV=production
      - PORT=8504
    ports: ["${TOKENISM_UI_HOST_PORT:-8504}:8504"]
    profiles: ["agents", "botz"]
    networks: [pmoves_app]

  # PMOVES Central UI - Main dashboard (port 4482)
  pmoves-ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    restart: unless-stopped
    env_file: [ env.shared.generated, env.shared, env.tier-ui, .env.generated, .env.local ]
    environment:
      - NODE_ENV=production
      # Supabase
      - NEXT_PUBLIC_SUPABASE_URL=${NEXT_PUBLIC_SUPABASE_URL:-http://localhost:8000}
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - NEXT_PUBLIC_SUPABASE_REST_URL=${NEXT_PUBLIC_SUPABASE_REST_URL:-http://localhost:3010}
      # Supabase (CLI uses port 54321)
      - NEXT_PUBLIC_SUPABASE_URL=${NEXT_PUBLIC_SUPABASE_URL:-http://localhost:54321}
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - NEXT_PUBLIC_SUPABASE_REST_URL=${NEXT_PUBLIC_SUPABASE_REST_URL:-http://localhost:54321/rest/v1}
      # Voice/TTS
      - NEXT_PUBLIC_FLUTE_GATEWAY_URL=${NEXT_PUBLIC_FLUTE_GATEWAY_URL:-http://localhost:8055}
      - NEXT_PUBLIC_FLUTE_WS_URL=${NEXT_PUBLIC_FLUTE_WS_URL:-ws://localhost:8056}
      # Agent Services (client-side needs localhost)
      - NEXT_PUBLIC_AGENT_ZERO_URL=${NEXT_PUBLIC_AGENT_ZERO_URL:-http://localhost:8080}
      - NEXT_PUBLIC_AGENT_ZERO_UI_URL=${NEXT_PUBLIC_AGENT_ZERO_UI_URL:-http://localhost:8081}
      - NEXT_PUBLIC_ARCHON_URL=${NEXT_PUBLIC_ARCHON_URL:-http://localhost:8091}
      - NEXT_PUBLIC_ARCHON_UI_URL=${NEXT_PUBLIC_ARCHON_UI_URL:-http://localhost:3737}
      # Knowledge & Search
      - NEXT_PUBLIC_HIRAG_URL=${NEXT_PUBLIC_HIRAG_URL:-http://localhost:8086}
      - NEXT_PUBLIC_OPEN_NOTEBOOK_API_URL=${NEXT_PUBLIC_OPEN_NOTEBOOK_API_URL:-http://localhost:8503}
      - NEXT_PUBLIC_TENSORZERO_UI_URL=${NEXT_PUBLIC_TENSORZERO_UI_URL:-http://localhost:4000}
      # Media & Ingestion
      - NEXT_PUBLIC_PRESIGN_URL=${NEXT_PUBLIC_PRESIGN_URL:-http://localhost:8088}
      - NEXT_PUBLIC_PMOVES_YT_BASE_URL=${NEXT_PUBLIC_PMOVES_YT_BASE_URL:-http://localhost:8077}
      - NEXT_PUBLIC_CHANNEL_MONITOR_STATS_URL=${NEXT_PUBLIC_CHANNEL_MONITOR_STATS_URL:-http://localhost:8097/api/monitor/stats}
      # Token Economy Simulation
      - NEXT_PUBLIC_TOKENISM_URL=${NEXT_PUBLIC_TOKENISM_URL:-http://localhost:8103}
      # Monitoring Stack
      - NEXT_PUBLIC_GRAFANA_URL=${NEXT_PUBLIC_GRAFANA_URL:-http://localhost:3002}
      - NEXT_PUBLIC_PROMETHEUS_URL=${NEXT_PUBLIC_PROMETHEUS_URL:-http://localhost:9090}
      - NEXT_PUBLIC_LOKI_URL=${NEXT_PUBLIC_LOKI_URL:-http://localhost:3100}
      # Server-side only (Docker hostnames OK)
      - POSTGREST_URL=http://host.docker.internal:54321
      - PRESIGN_SHARED_SECRET=${PRESIGN_SHARED_SECRET}
      - RENDER_WEBHOOK_URL=${RENDER_WEBHOOK_URL:-http://render-webhook:8085/comfy/webhook}
      - OPEN_NOTEBOOK_API_URL=${OPEN_NOTEBOOK_API_URL:-http://open-notebook:8503}
      - TOKENISM_URL=${TOKENISM_URL:-http://pmoves-tokenism-simulator-1:8100}
    ports:
      - "4482:3000"
    # Note: flute-gateway is optional (for voice features). Start with workers profile for full functionality.
    networks: [ pmoves_app, pmoves_api, supabase_net ]
    profiles: [ "ui" ]
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Session Context Worker - Transforms Claude Code session context to Hi-RAG KB entries
  session-context-worker:
    <<: *id003
    image: ${SESSION_CONTEXT_WORKER_IMAGE:-ghcr.io/powerfulmoves/pmoves-session-context-worker:latest}
    restart: unless-stopped
    environment:
    - PORT=8100
    - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.shared/env.tier-worker has credentials: nats://nats:pmoves@nats:4222
    - PORT=8100
    - HIRAG_INGEST_URL=${HIRAG_INGEST_URL:-http://hi-rag-gateway-v2:8086/ingest}
    ports:
    - 8102:8100
    profiles:
    - workers
    networks:
    - pmoves_app
    - pmoves_bus
    depends_on:
      - hi-rag-gateway-v2

  # Comfy Watcher - ComfyUI output watcher for NATS integration
  comfy-watcher:
    build:
      context: .
      dockerfile: services/comfy-watcher/Dockerfile
    restart: unless-stopped
    <<: *id003
    environment:
      # NATS_URL from env.shared/env.tier-worker has credentials: nats://nats:pmoves@nats:4222
      - MINIO_ENDPOINT=${MINIO_ENDPOINT:-minio:9000}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - MINIO_BUCKET=${MINIO_BUCKET:-pmoves-comfyui}
      - PUBLIC_BASE_URL=${PUBLIC_BASE_URL:-http://minio:9000}
      - PRESIGN_EXPIRES_HOURS=${PRESIGN_EXPIRES_HOURS:-24}
    depends_on:
      nats:
        condition: service_started
      minio:
        condition: service_started
    volumes:
      - comfy-watcher-output:/data
      - comfy-watcher-state:/state
    profiles: ["orchestration", "workers"]
    networks: [pmoves_bus, pmoves_data]
    healthcheck:
      test: ["CMD", "python3", "-c", "from watcher import load_state; load_state()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Gateway Agent - Orchestrates 100+ MCP tools via Agent Zero MCP API
  gateway-agent:
    build: ./services/gateway-agent
    restart: unless-stopped
    env_file:
      - env.shared
      - .env.generated
    environment:
      - PORT=8110
      - AGENT_ZERO_URL=${AGENT_ZERO_URL:-http://agent-zero:8080}
      - CIPHER_URL=${CIPHER_URL:-http://pmoves-botz-cipher:8000}
      - TENSORZERO_URL=${TENSORZERO_URL:-http://tensorzero-gateway:3000}
      - SUPABASE_URL=${SUPABASE_URL:-http://host.docker.internal:54321}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - TOOL_CACHE_TTL=${TOOL_CACHE_TTL:-300}
    ports:
      - "8110:8110"
    profiles: ["agents"]
    networks: [pmoves_api, pmoves_app, pmoves_bus]
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8110/healthz', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # GitHub Runner Control - Manages self-hosted GitHub runners
  github-runner-ctl:
    build: ./services/github-runner-ctl
    restart: unless-stopped
    <<: *id005
    environment:
      - PORT=8104
      - NATS_URL=${NATS_URL:-nats://nats:4222}
    # NATS_URL from env.tier-agent has credentials: nats://nats:pmoves@nats:4222
      - PORT=8104
      - GITHUB_PAT_FILE=${GITHUB_PAT_FILE:-/run/secrets/github_pat}
      - GITHUB_REPOSITORIES=${GITHUB_REPOSITORIES:-POWERFULMOVES/PMOVES.AI}
      - REFRESH_INTERVAL_SECONDS=${GITHUB_RUNNER_REFRESH_INTERVAL:-60}
      - LOG_LEVEL=${GITHUB_RUNNER_CTL_LOG_LEVEL:-INFO}
    depends_on: [ nats ]
    ports: ["8104:8104"]
    volumes:
      - ./services/github-runner-ctl/config:/app/config:ro
      - ./secrets/github_pat:/run/secrets/github_pat:ro
    profiles: ["orchestration", "workers"]
    networks: [pmoves_api, pmoves_bus, pmoves_monitoring]
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8104/healthz', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  invidious-db:
    image: postgres:14
    restart: unless-stopped
    environment:
    - POSTGRES_DB=${INVIDIOUS_PG_DB:-invidious}
    - POSTGRES_USER=${INVIDIOUS_PG_USER:-kemal}
    - POSTGRES_PASSWORD=${INVIDIOUS_PG_PASSWORD:-kemal}
    volumes:
    - invidious-postgres-data:/var/lib/postgresql/data
    - ./services/invidious/config/sql:/config/sql:ro
    - ./services/invidious/init-invidious-db.sh:/docker-entrypoint-initdb.d/init-invidious-db.sh:ro
    healthcheck:
      test:
      - CMD-SHELL
      - pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB -h 127.0.0.1
      interval: 10s
      timeout: 5s
      retries: 12
    profiles:
    - invidious
    networks:
    - pmoves_data
    - pmoves_app
  invidious-companion:
    # Pinned 2025-02-04: Latest stable from Invidious GitHub releases (v2.20250913.0)
    image: quay.io/invidious/invidious-companion:2025.09.13-0065a3e
    restart: unless-stopped
    env_file:
    - env.shared
    environment:
    - PORT=8282
    - HOST=0.0.0.0
    - SERVER_SECRET_KEY=${INVIDIOUS_COMPANION_KEY:-60eec5b733160c57}
    - CACHE_DIRECTORY=/var/tmp/youtubei.js
    - SERVER_BASE_URL=${INVIDIOUS_COMPANION_PUBLIC_URL:-}
    - YOUTUBE_API_KEY=${INVIDIOUS_COMPANION_YOUTUBE_API_KEY:-}
    - YOUTUBEI_CLIENT=${INVIDIOUS_COMPANION_YOUTUBEI_CLIENT:-IOS}
    - YOUTUBEI_API_BASE=${INVIDIOUS_COMPANION_CA_URL:-https://www.youtube.com}
    volumes:
    - invidious-companion-cache:/var/tmp/youtubei.js
    ports:
    - ${INVIDIOUS_COMPANION_PORT:-8282}:8282
    profiles:
    - invidious
    networks:
    - pmoves_app
    - pmoves_bus
  invidious:
    # Pinned 2025-02-04: Latest stable from Invidious GitHub releases (v2.20250913.0)
    image: quay.io/invidious/invidious:2025.09.13-c8b4325
    restart: unless-stopped
    env_file:
    - env.shared
    environment:
    - "INVIDIOUS_CONFIG=db:\n  dbname: ${INVIDIOUS_PG_DB:-invidious}\n  user: ${INVIDIOUS_PG_USER:-kemal}\n\
      \  password: ${INVIDIOUS_PG_PASSWORD:-kemal}\n  host: invidious-db\n  port:\
      \ 5432\n  check_tables: true\ndomain: ${INVIDIOUS_DOMAIN:-}\nexternal_port:\
      \ ${INVIDIOUS_EXTERNAL_PORT:-3000}\nhttps_only: ${INVIDIOUS_HTTPS_ONLY:-false}\n\
      hmac_key: \"${INVIDIOUS_HMAC_KEY:-c51f3b3a42fbf044a9b1094eadbc79743b0d859999441d3dcfce55f5ad64a9a1}\"\ninvidious_companion:\n\
      \  - private_url: \"http://invidious-companion:8282\"\n    public_url: \"${INVIDIOUS_COMPANION_PUBLIC_URL:-http://localhost:8281}\"\
      \ninvidious_companion_key: \"${INVIDIOUS_COMPANION_KEY:-60eec5b733160c57}\"\nstatistics_enabled: ${INVIDIOUS_STATISTICS_ENABLED:-false}\nuse_innertube_for_captions:\
      \ ${INVIDIOUS_USE_INNERTUBE_CAPTIONS:-true}\nredirector:\n  use_invidious_redirector:\
      \ ${INVIDIOUS_USE_REDIRECTOR:-true}\n  redirector_url: \"${INVIDIOUS_REDIRECTOR_URL:-https://redirect.invidious.io}\"\
      \n"
    ports:
    - ${INVIDIOUS_PORT:-3000}:3000
    depends_on:
      invidious-db:
        condition: service_healthy
      invidious-companion:
        condition: service_started
    healthcheck:
      test:
      - CMD-SHELL
      - wget -qO- http://127.0.0.1:3000/api/v1/stats >/dev/null 2>&1 || wget -qO- http://127.0.0.1:3000/ >/dev/null 2>&1
      interval: 30s
      timeout: 5s
      retries: 3
    profiles:
    - invidious
    networks:
    - pmoves_app
    - pmoves_bus
  grayjay-plugin-host:
    build: ./services/grayjay-plugin-host
    restart: unless-stopped
    env_file:
    - env.shared.generated
    - env.shared
    - .env.generated
    - .env.local
    environment:
    - JELLYFIN_PUBLIC_URL=${JELLYFIN_PUBLIC_BASE_URL:-http://localhost:8096}
    - GRAYJAY_PLUGIN_HOST_PUBLIC_URL=${GRAYJAY_PLUGIN_HOST_PUBLIC_URL:-http://localhost:9096}
    - GRAYJAY_PLUGIN_REGISTRY_TITLE=${GRAYJAY_PLUGIN_REGISTRY_TITLE:-PMOVES Plugin
      Registry}
    - GRAYJAY_JELLYFIN_PLUGIN_NAME=${GRAYJAY_JELLYFIN_PLUGIN_NAME:-PMOVES Jellyfin}
    - GRAYJAY_JELLYFIN_PLUGIN_DESCRIPTION=${GRAYJAY_JELLYFIN_PLUGIN_DESCRIPTION:-Self-hosted
      Jellyfin connector for PMOVES}
    - GRAYJAY_JELLYFIN_PLUGIN_ID=${GRAYJAY_JELLYFIN_PLUGIN_ID:-pmoves-jellyfin}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${GRAYJAY_PLUGIN_HOST_PORT:-9096}:8080
    profiles:
    - grayjay
    networks:
    - pmoves_app
    - pmoves_bus
  grayjay-server:
    image: registry.gitlab.futo.org/videostreaming/grayjay/grayjay:latest
    restart: unless-stopped
    env_file:
    - env.shared.generated
    - env.shared
    - .env.generated
    - .env.local
    environment:
    - GRAYJAY_PLUGIN_REGISTRY_URL=${GRAYJAY_PLUGIN_REGISTRY_URL:-http://grayjay-plugin-host:8080/plugins}
    - GRAYJAY_SERVER_BIND=${GRAYJAY_SERVER_BIND:-0.0.0.0}
    - GRAYJAY_SERVER_PORT=${GRAYJAY_SERVER_PORT:-9095}
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
    ports:
    - ${GRAYJAY_SERVER_PORT:-9095}:9095
    depends_on:
      grayjay-plugin-host:
        condition: service_started
    profiles:
    - grayjay
    networks:
    - pmoves_app
    - pmoves_bus
  cloudflared:
    image: cloudflare/cloudflared:2024.8.0
    restart: unless-stopped
    command:
    - /bin/sh
    - -c
    - "if [ -n \"$$CLOUDFLARE_TUNNEL_TOKEN\" ]; then\n  exec cloudflared tunnel --no-autoupdate\
      \ run;\nelif [ -n \"$$CLOUDFLARE_TUNNEL_NAME\" ]; then\n  exec cloudflared tunnel\
      \ --no-autoupdate run \"$$CLOUDFLARE_TUNNEL_NAME\";\nelse\n  echo \"Set CLOUDFLARE_TUNNEL_TOKEN\
      \ or CLOUDFLARE_TUNNEL_NAME before starting cloudflared.\";\n  exit 1;\nfi\n"
    env_file:
    - env.shared.generated
    - env.shared
    - .env.generated
    - .env.local
    environment:
    - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN:-}
    - CLOUDFLARE_TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN:-}
    - CLOUDFLARE_TUNNEL_NAME=${CLOUDFLARE_TUNNEL_NAME:-}
    volumes:
    - ${CLOUDFLARE_CREDENTIALS_DIR:-./cloudflared}:/home/nonroot/.cloudflared:rw
    profiles:
    - cloudflare
    networks:
    - pmoves_app
  invidious-companion-proxy:
    build: ./services/invidious-companion-proxy
    restart: unless-stopped
    depends_on:
      invidious-companion:
        condition: service_started
    ports:
    - 8281:80
    profiles:
    - invidious
    networks:
    - pmoves_app
    - pmoves_bus
    environment:
    - DOCKED_MODE=${DOCKED_MODE:-true}
    - PARENT_SYSTEM=${PARENT_SYSTEM:-PMOVES.AI}
    - PARENT_VERSION=${PARENT_VERSION:-1.0.0-hardened}
volumes:
  neo4j-data: {}
  minio-data: {}
  # Legacy volume (kept for backward compatibility during migration)
  supabase-data: {}
  # 2025 Supabase integrated volumes
  supabase-db-data: {}
  supabase-storage-data: {}
  notebook-sync-data: {}
  tensorzero-clickhouse-data: {}
  invidious-postgres-data: {}
  invidious-companion-cache: {}
  pmoves-ollama-models: {}
  comfy-watcher-output: {}
  comfy-watcher-state: {}
networks:
  pmoves_data:
    name: pmoves_data
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
      - subnet: 172.30.4.0/24
        gateway: 172.30.4.1
  pmoves_api:
    name: pmoves_api
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
      - subnet: 172.30.1.0/24
        gateway: 172.30.1.1
  pmoves_app:
    name: pmoves_app
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
      - subnet: 172.30.2.0/24
        gateway: 172.30.2.1
  pmoves_bus:
    name: pmoves_bus
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
      - subnet: 172.30.3.0/24
        gateway: 172.30.3.1
  pmoves_monitoring:
    name: pmoves_monitoring
    driver: bridge
    internal: true
    ipam:
      driver: default
      config:
      - subnet: 172.30.5.0/24
        gateway: 172.30.5.1
  # NOTE: supabase_net no longer needed - Supabase services now use internal pmoves_data/pmoves_api networks
  # pmoves and cataclysm kept for external service compatibility
  pmoves:
    external: true
    name: pmoves-net
  cataclysm:
    external: true
    name: cataclysm-net
  # External network for services requiring internet access (YouTube API, LLM providers, etc.)
  pmoves_external:
    name: pmoves_external
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet: 172.30.6.0/24
        gateway: 172.30.6.1
