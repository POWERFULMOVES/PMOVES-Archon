# GPU Model Registry Configuration
# =================================
# Defines known models and their VRAM requirements for GPU Orchestrator.

models:
  # Ollama Models (Primary Local Provider)
  - id: "qwen3:8b"
    provider: ollama
    vram_mb: 6144
    description: "Qwen3 8B - Fast reasoning and code"
    priority_default: 5
    quantization: "Q4_K_M"
    context_length: 8192

  - id: "qwen3:32b"
    provider: ollama
    vram_mb: 20480
    description: "Qwen3 32B - Advanced reasoning"
    priority_default: 7
    quantization: "Q4_K_M"
    context_length: 8192

  - id: "qwen3:1.7b"
    provider: ollama
    vram_mb: 1536
    description: "Qwen3 1.7B - Lightweight tasks"
    priority_default: 3
    quantization: "Q4_K_M"
    context_length: 4096

  - id: "nomic-embed-text"
    provider: ollama
    vram_mb: 512
    description: "Nomic Embed Text - Embeddings"
    priority_default: 3
    context_length: 8192

  - id: "llama3.2:3b"
    provider: ollama
    vram_mb: 2048
    description: "Llama 3.2 3B - General purpose"
    priority_default: 4
    quantization: "Q4_K_M"

  - id: "codellama:7b"
    provider: ollama
    vram_mb: 4096
    description: "Code Llama 7B - Code generation"
    priority_default: 5
    quantization: "Q4_K_M"
    context_length: 16384

  - id: "deepseek-coder:6.7b"
    provider: ollama
    vram_mb: 4608
    description: "DeepSeek Coder 6.7B"
    priority_default: 5
    context_length: 16384

  # TTS Models (Ultimate TTS Studio)
  - id: "kokoro"
    provider: tts
    vram_mb: 2048
    description: "Kokoro TTS - Japanese/English"
    priority_default: 4

  - id: "f5-tts"
    provider: tts
    vram_mb: 3072
    description: "F5-TTS - High quality synthesis"
    priority_default: 4

  - id: "voxcpm"
    provider: tts
    vram_mb: 2560
    description: "VoxCPM - Voice cloning capable"
    priority_default: 4

  - id: "kitten-tts"
    provider: tts
    vram_mb: 1536
    description: "KittenTTS - Fast and light"
    priority_default: 3

  - id: "melo-tts"
    provider: tts
    vram_mb: 1024
    description: "MeloTTS - Multilingual"
    priority_default: 3

  - id: "piper"
    provider: tts
    vram_mb: 512
    description: "Piper TTS - Fast CPU/GPU"
    priority_default: 2

  # vLLM Models (if configured)
  - id: "default"
    provider: vllm
    vram_mb: 16384
    description: "Default vLLM model"
    priority_default: 8

# Thresholds for automatic actions
thresholds:
  vram_warning_percent: 80
  vram_critical_percent: 95
  idle_timeout_seconds: 300
  max_queued_requests: 10

# Hardware specifications
rtx5090:
  name: "NVIDIA GeForce RTX 5090"
  total_vram_mb: 32768
  system_reserve_mb: 2048
  compute_capability: "12.0"
  cuda_cores: 21760
  tensor_cores: 680

rtx4090:
  name: "NVIDIA GeForce RTX 4090"
  total_vram_mb: 24576
  system_reserve_mb: 2048
  compute_capability: "8.9"

rtx3090ti:
  name: "NVIDIA GeForce RTX 3090 Ti"
  total_vram_mb: 24576
  system_reserve_mb: 2048
  compute_capability: "8.6"

jetson_orin_nano:
  name: "NVIDIA Jetson Orin Nano"
  total_vram_mb: 8192  # Shared with system RAM
  system_reserve_mb: 4096
  compute_capability: "8.7"
