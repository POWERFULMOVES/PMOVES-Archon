[
  {
    "name": "PMOVES Audio Analysis Pipeline",
    "nodes": [
      {
        "parameters": {
          "path": "pmoves/audio-analysis",
          "options": {
            "responseData": "{\"ok\":true,\"message\":\"Audio analysis started\"}"
          },
          "httpMethod": "POST"
        },
        "id": "wh_audio",
        "name": "Webhook Trigger",
        "type": "n8n-nodes-base.webhook",
        "typeVersion": 1,
        "position": [200, 300]
      },
      {
        "parameters": {
          "functionCode": "const body = $json;\nconst assetUrl = body.asset_url || body.presigned_get || body.s3_uri;\nif (!assetUrl) {\n  throw new Error('asset_url is required for audio analysis');\n}\n\n// Parse S3 URI if provided\nlet bucket = body.bucket;\nlet key = body.key;\nif (assetUrl.startsWith('s3://')) {\n  const parts = assetUrl.replace('s3://', '').split('/');\n  bucket = parts[0];\n  key = parts.slice(1).join('/');\n}\n\nconst result = {\n  asset_url: assetUrl,\n  bucket: bucket,\n  key: key,\n  namespace: body.namespace || 'pmoves',\n  source: body.source || 'ingestion_hub',\n  filename: body.filename || key?.split('/').pop() || 'audio',\n  language: body.language || null,\n  diarize: body.diarize !== false,\n  metadata: body.metadata || {},\n  auto_research: body.auto_research || false,\n  received_at: body.received_at || new Date().toISOString()\n};\n\nreturn [{ json: result }];"
        },
        "id": "prepare_audio",
        "name": "Prepare Audio Request",
        "type": "n8n-nodes-base.function",
        "typeVersion": 2,
        "position": [460, 300]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "http://ffmpeg-whisper:8078/transcribe",
          "sendBody": true,
          "body": "={{ JSON.stringify({ bucket: $json.bucket, key: $json.key, language: $json.language, diarize: $json.diarize }) }}",
          "options": {
            "timeout": 300000,
            "bodyContentType": "json"
          }
        },
        "id": "transcribe",
        "name": "FFmpeg-Whisper Transcribe",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4,
        "position": [720, 200]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "http://media-audio:8082/process",
          "sendBody": true,
          "body": "={{ JSON.stringify({ bucket: $node['Prepare Audio Request'].json.bucket, key: $node['Prepare Audio Request'].json.key }) }}",
          "options": {
            "timeout": 300000,
            "bodyContentType": "json"
          }
        },
        "id": "analyze_audio",
        "name": "Media-Audio Analysis",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4,
        "position": [720, 400]
      },
      {
        "parameters": {
          "functionCode": "const transcriptResult = $node['FFmpeg-Whisper Transcribe'].json;\nconst audioResult = $node['Media-Audio Analysis'].json;\nconst original = $node['Prepare Audio Request'].json;\n\nconst merged = {\n  asset_url: original.asset_url,\n  namespace: original.namespace,\n  source: original.source,\n  filename: original.filename,\n  transcript: {\n    text: transcriptResult.text || '',\n    language: transcriptResult.language || 'en',\n    segments: transcriptResult.segments || [],\n    word_segments: transcriptResult.word_segments || [],\n    speakers: transcriptResult.speakers || {}\n  },\n  analysis: {\n    emotions: audioResult.emotions || [],\n    features: audioResult.features || {},\n    duration_sec: audioResult.features?.global?.duration || 0\n  },\n  metadata: original.metadata,\n  auto_research: original.auto_research,\n  processed_at: new Date().toISOString()\n};\n\nreturn [{ json: merged }];"
        },
        "id": "merge_results",
        "name": "Merge Results",
        "type": "n8n-nodes-base.function",
        "typeVersion": 2,
        "position": [980, 300]
      },
      {
        "parameters": {
          "functionCode": "const data = $json;\nconst now = new Date().toISOString();\nconst namespace = data.namespace;\nconst filename = data.filename;\nconst slug = filename.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/\\.[^.]+$/, '');\n\n// Build CGP constellation for audio content\nconst points = [\n  {\n    id: `audio:${slug}`,\n    modality: 'audio',\n    ref_id: data.asset_url,\n    proj: 1.0,\n    summary: `Audio file: ${filename}`\n  }\n];\n\n// Add transcript as text point\nif (data.transcript?.text) {\n  points.push({\n    id: `transcript:${slug}`,\n    modality: 'text',\n    ref_id: null,\n    proj: 0.9,\n    summary: data.transcript.text.slice(0, 500) + (data.transcript.text.length > 500 ? '...' : '')\n  });\n}\n\n// Calculate spectrum from emotion analysis\nconst emotions = data.analysis?.emotions || [];\nconst avgEmotionScore = emotions.length > 0 \n  ? emotions.reduce((sum, e) => sum + (e.score || 0), 0) / emotions.length \n  : 0.5;\nconst clarity = data.analysis?.features?.global?.rms || 0.7;\n\nconst spectrum = [avgEmotionScore, Math.min(1, clarity)];\n\nconst constellation = {\n  id: `audio.analysis.${slug}`,\n  summary: data.transcript?.text?.slice(0, 200) || `Audio: ${filename}`,\n  spectrum: spectrum,\n  points: points,\n  meta: {\n    namespace: namespace,\n    source: data.source,\n    language: data.transcript?.language,\n    duration_sec: data.analysis?.duration_sec,\n    speaker_count: Object.keys(data.transcript?.speakers || {}).length,\n    emotion_count: emotions.length\n  }\n};\n\nconst cgp = {\n  spec: 'chit.cgp.v0.1',\n  summary: `Audio analysis: ${filename}`,\n  created_at: now,\n  super_nodes: [\n    {\n      id: `media:${namespace}`,\n      label: namespace,\n      summary: 'Audio content',\n      constellations: [constellation]\n    }\n  ],\n  meta: {\n    source: 'n8n.audio.analysis',\n    namespace: namespace,\n    pipeline: 'audio_analysis'\n  }\n};\n\nreturn [{ json: { data: data, cgp_envelope: { type: 'geometry.cgp.v1', data: cgp } } }];"
        },
        "id": "build_cgp",
        "name": "Build CGP Envelope",
        "type": "n8n-nodes-base.function",
        "typeVersion": 2,
        "position": [1240, 300]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "http://hi-rag-gateway-v2:8086/geometry/event",
          "sendBody": true,
          "body": "={{ JSON.stringify($json.cgp_envelope) }}",
          "options": {
            "timeout": 30000,
            "bodyContentType": "json"
          }
        },
        "id": "index_hirag",
        "name": "Index to Hi-RAG",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4,
        "position": [1500, 300]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "http://agent-zero:8080/events/publish",
          "sendBody": true,
          "body": "={{ JSON.stringify({ subject: 'analysis.audio.v1', data: $node['Build CGP Envelope'].json.data }) }}",
          "options": {
            "timeout": 10000,
            "bodyContentType": "json"
          }
        },
        "id": "publish_nats",
        "name": "Publish NATS Event",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4,
        "position": [1500, 500]
      },
      {
        "parameters": {
          "conditions": {
            "boolean": [
              {
                "value1": "={{ $node['Build CGP Envelope'].json.data.auto_research }}",
                "value2": true
              }
            ]
          }
        },
        "id": "check_research",
        "name": "Auto Research?",
        "type": "n8n-nodes-base.if",
        "typeVersion": 1,
        "position": [1760, 300]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "http://n8n:5678/webhook/pmoves/deepresearch",
          "sendBody": true,
          "body": "={{ JSON.stringify({ query: $node['Build CGP Envelope'].json.data.transcript?.text?.slice(0, 1000), source: 'audio_analysis', context: { asset_url: $node['Build CGP Envelope'].json.data.asset_url } }) }}",
          "options": {
            "timeout": 10000,
            "bodyContentType": "json"
          }
        },
        "id": "trigger_research",
        "name": "Trigger DeepResearch",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4,
        "position": [2020, 200]
      }
    ],
    "connections": {
      "Webhook Trigger": {
        "main": [[{"node": "Prepare Audio Request", "type": "main", "index": 0}]]
      },
      "Prepare Audio Request": {
        "main": [
          [
            {"node": "FFmpeg-Whisper Transcribe", "type": "main", "index": 0},
            {"node": "Media-Audio Analysis", "type": "main", "index": 0}
          ]
        ]
      },
      "FFmpeg-Whisper Transcribe": {
        "main": [[{"node": "Merge Results", "type": "main", "index": 0}]]
      },
      "Media-Audio Analysis": {
        "main": [[{"node": "Merge Results", "type": "main", "index": 0}]]
      },
      "Merge Results": {
        "main": [[{"node": "Build CGP Envelope", "type": "main", "index": 0}]]
      },
      "Build CGP Envelope": {
        "main": [
          [
            {"node": "Index to Hi-RAG", "type": "main", "index": 0},
            {"node": "Publish NATS Event", "type": "main", "index": 0},
            {"node": "Auto Research?", "type": "main", "index": 0}
          ]
        ]
      },
      "Auto Research?": {
        "main": [
          [{"node": "Trigger DeepResearch", "type": "main", "index": 0}],
          []
        ]
      }
    },
    "settings": {},
    "staticData": null,
    "active": false,
    "meta": {
      "description": "Audio analysis pipeline: transcription (FFmpeg-Whisper) + emotion/feature analysis (Media-Audio) + Hi-RAG indexing"
    },
    "pinData": null,
    "versionId": "audio-analysis-v1",
    "versionCounter": 1,
    "triggerCount": 0,
    "tags": ["pmoves", "audio", "analysis", "transcription"]
  }
]
